{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "790440c6",
   "metadata": {},
   "source": [
    "### Normalization script already executed in jupyter and the code and output screenshot pasted in word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94c8293c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: c:\\Users\\HP\\Downloads\\job-trends-app\\job-trends-app\\.venv\\Scripts\\python.exe\n",
      "pymysql: 1.4.6\n",
      "sqlalchemy: 2.0.44\n",
      "pandas: 2.3.3\n",
      "DB reachable (SELECT 1): 1\n",
      "Skipping table creation/writes- already exisits.\n",
      "Loaded existing data.\n",
      "{'max_job_id': 19472, 'max_company_id': 0, 'max_location_id': 42, 'max_industry_id': 0, 'max_skill_id': 0}\n",
      "Next IDs: {'next_job_id': 19473, 'next_company_id': 1, 'next_location_id': 43, 'next_industry_id': 1, 'next_skill_id': 1}\n",
      "Loaded 200 sample rows for demo.\n",
      " flush 200 jobs and 0 job_skills\n",
      "\n",
      "✅ Processed 200 rows in 0.0s\n",
      "\n",
      " Skipping writing lookup tables (companies, locations, industries, skills).\n",
      "\n",
      "✅ Normalization demo complete.\n",
      "Companies: 0 Locations: 42 Industries: 0 Skills: 0\n"
     ]
    }
   ],
   "source": [
    "import sys, time, re, subprocess\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "# ------------------ CONFIG (edit) ------------------\n",
    "MYSQL_USER = \"root\"\n",
    "MYSQL_PASS = \"pass123\"\n",
    "MYSQL_HOST = \"127.0.0.1\"\n",
    "MYSQL_PORT = 3306\n",
    "MYSQL_DB   = \"job_trends\"\n",
    "RAW_TABLE  = \"jobs_in_data\"\n",
    "CHUNKSIZE  = 20000\n",
    "JOBS_BATCH = 1000\n",
    "DEMO_MODE  = True   # <<=== ✅ Set True for safe demo (no DB writes)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "def ensure(pkg):\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "    except ModuleNotFoundError:\n",
    "        print(f\"Installing {pkg} ...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg, \"--quiet\"])\n",
    "\n",
    "for p in (\"pymysql\",\"sqlalchemy\",\"pandas\"):\n",
    "    ensure(p)\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import sqlalchemy\n",
    "import pymysql\n",
    "from sqlalchemy.exc import IntegrityError\n",
    "\n",
    "print(\"Python:\", sys.executable)\n",
    "print(\"pymysql:\", pymysql.__version__)\n",
    "print(\"sqlalchemy:\", sqlalchemy.__version__)\n",
    "print(\"pandas:\", pd.__version__)\n",
    "\n",
    "# Build DB engine\n",
    "db_url = f\"mysql+pymysql://{MYSQL_USER}:{quote_plus(MYSQL_PASS)}@{MYSQL_HOST}:{MYSQL_PORT}/{MYSQL_DB}?charset=utf8mb4\"\n",
    "engine = create_engine(db_url, pool_recycle=3600, pool_pre_ping=True)\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        print(\"DB reachable (SELECT 1):\", conn.execute(text(\"SELECT 1\")).scalar())\n",
    "except Exception as e:\n",
    "    print(\"❌ Cannot reach DB; fix connection first.\")\n",
    "    raise\n",
    "\n",
    "# Create tables if needed (demo-safe)\n",
    "if not DEMO_MODE:\n",
    "    create_sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS companies (\n",
    "      Company_ID INT PRIMARY KEY,\n",
    "      Company_Name VARCHAR(255) UNIQUE\n",
    "    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "\n",
    "    CREATE TABLE IF NOT EXISTS locations (\n",
    "      Location_ID INT PRIMARY KEY,\n",
    "      Location VARCHAR(255) UNIQUE\n",
    "    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "\n",
    "    CREATE TABLE IF NOT EXISTS industries (\n",
    "      Industry_ID INT PRIMARY KEY,\n",
    "      Industry VARCHAR(255) UNIQUE\n",
    "    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "\n",
    "    CREATE TABLE IF NOT EXISTS skills (\n",
    "      Skill_ID INT PRIMARY KEY,\n",
    "      Skill_Name VARCHAR(255) UNIQUE\n",
    "    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "\n",
    "    CREATE TABLE IF NOT EXISTS jobs (\n",
    "      Job_ID INT PRIMARY KEY,\n",
    "      Job_Title VARCHAR(255),\n",
    "      Job_Description TEXT,\n",
    "      Company_ID INT,\n",
    "      Location_ID INT,\n",
    "      Industry_ID INT,\n",
    "      Salary_USD VARCHAR(100),\n",
    "      Employment_Type VARCHAR(100),\n",
    "      Experience_Level VARCHAR(100),\n",
    "      Work_Setting VARCHAR(100)\n",
    "    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "\n",
    "    CREATE TABLE IF NOT EXISTS job_skills (\n",
    "      Job_ID INT,\n",
    "      Skill_ID INT,\n",
    "      PRIMARY KEY (Job_ID, Skill_ID)\n",
    "    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "    \"\"\"\n",
    "    with engine.begin() as conn:\n",
    "        for stmt in create_sql.strip().split(';'):\n",
    "            stmt = stmt.strip()\n",
    "            if stmt:\n",
    "                conn.execute(text(stmt))\n",
    "    print(\"Ensured normalized tables exist.\")\n",
    "else:\n",
    "    print(\"Skipping table creation/writes- already exisits.\")\n",
    "\n",
    "# Load lookup metadata\n",
    "with engine.begin() as conn:\n",
    "    max_job_id = int(conn.execute(text(\"SELECT COALESCE(MAX(Job_ID), 0) FROM jobs\")).scalar() or 0)\n",
    "    max_company_id = int(conn.execute(text(\"SELECT COALESCE(MAX(Company_ID), 0) FROM companies\")).scalar() or 0)\n",
    "    max_location_id = int(conn.execute(text(\"SELECT COALESCE(MAX(Location_ID), 0) FROM locations\")).scalar() or 0)\n",
    "    max_industry_id = int(conn.execute(text(\"SELECT COALESCE(MAX(Industry_ID), 0) FROM industries\")).scalar() or 0)\n",
    "    max_skill_id = int(conn.execute(text(\"SELECT COALESCE(MAX(Skill_ID), 0) FROM skills\")).scalar() or 0)\n",
    "\n",
    "    existing_companies = {r[1]: r[0] for r in conn.execute(text(\"SELECT Company_ID, Company_Name FROM companies\")).fetchall()}\n",
    "    existing_locations = {r[1]: r[0] for r in conn.execute(text(\"SELECT Location_ID, Location FROM locations\")).fetchall()}\n",
    "    existing_industries = {r[1]: r[0] for r in conn.execute(text(\"SELECT Industry_ID, Industry FROM industries\")).fetchall()}\n",
    "    existing_skills = {r[1]: r[0] for r in conn.execute(text(\"SELECT Skill_ID, Skill_Name FROM skills\")).fetchall()}\n",
    "\n",
    "print(\"Loaded existing data.\")\n",
    "print(dict(\n",
    "    max_job_id=max_job_id, max_company_id=max_company_id,\n",
    "    max_location_id=max_location_id, max_industry_id=max_industry_id,\n",
    "    max_skill_id=max_skill_id\n",
    "))\n",
    "\n",
    "companies_map = dict(existing_companies)\n",
    "locations_map = dict(existing_locations)\n",
    "industries_map = dict(existing_industries)\n",
    "skills_map = dict(existing_skills)\n",
    "\n",
    "next_company_id = max_company_id + 1\n",
    "next_location_id = max_location_id + 1\n",
    "next_industry_id = max_industry_id + 1\n",
    "next_skill_id = max_skill_id + 1\n",
    "next_job_id = max_job_id + 1\n",
    "\n",
    "print(\"Next IDs:\", dict(\n",
    "    next_job_id=next_job_id,\n",
    "    next_company_id=next_company_id,\n",
    "    next_location_id=next_location_id,\n",
    "    next_industry_id=next_industry_id,\n",
    "    next_skill_id=next_skill_id\n",
    "))\n",
    "\n",
    "def find_col(cols, candidates):\n",
    "    m = {c.lower(): c for c in cols}\n",
    "    for n in candidates:\n",
    "        if n.lower() in m:\n",
    "            return m[n.lower()]\n",
    "    return None\n",
    "\n",
    "def flush_jobs(engine, jobs_batch, job_skills_batch):\n",
    "    if DEMO_MODE:\n",
    "        print(f\" flush {len(jobs_batch)} jobs and {len(job_skills_batch)} job_skills\")\n",
    "        jobs_batch.clear(); job_skills_batch.clear()\n",
    "        return\n",
    "    if not jobs_batch and not job_skills_batch:\n",
    "        return\n",
    "    with engine.begin() as conn:\n",
    "        if jobs_batch:\n",
    "            dfj = pd.DataFrame(jobs_batch)\n",
    "            dfj.to_sql('jobs', con=conn, if_exists='append', index=False, method='multi')\n",
    "        if job_skills_batch:\n",
    "            dfjs = pd.DataFrame(job_skills_batch)\n",
    "            dfjs.to_sql('job_skills', con=conn, if_exists='append', index=False, method='multi')\n",
    "    print(f\"Flushed {len(jobs_batch)} jobs and {len(job_skills_batch)} job_skills.\")\n",
    "    jobs_batch.clear(); job_skills_batch.clear()\n",
    "\n",
    "# Read & simulate normalization\n",
    "reader = pd.read_sql(f\"SELECT * FROM `{RAW_TABLE}` LIMIT 200\", engine)  # smaller read for demo\n",
    "print(f\"Loaded {len(reader)} sample rows for demo.\")\n",
    "reader = reader.dropna(how='all').copy()\n",
    "reader.columns = [c.strip() for c in reader.columns]\n",
    "\n",
    "job_col = find_col(reader.columns, [\"job_title\",\"title\"])\n",
    "desc_col = find_col(reader.columns, [\"job_description\",\"description\"])\n",
    "company_col = find_col(reader.columns, [\"company\",\"company_name\"])\n",
    "location_col = find_col(reader.columns, [\"location\",\"company_location\"])\n",
    "industry_col = find_col(reader.columns, [\"industry\",\"sector\"])\n",
    "skills_col = find_col(reader.columns, [\"skills\",\"key_skills\"])\n",
    "\n",
    "jobs_batch = []; job_skills_batch = []\n",
    "processed = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for idx, row in reader.iterrows():\n",
    "    jt = row.get(job_col)\n",
    "    jd = row.get(desc_col)\n",
    "    cname = row.get(company_col)\n",
    "    loc = row.get(location_col)\n",
    "    ind = row.get(industry_col)\n",
    "    sks = row.get(skills_col)\n",
    "\n",
    "    if cname and cname not in companies_map:\n",
    "        companies_map[cname] = next_company_id; next_company_id += 1\n",
    "    if loc and loc not in locations_map:\n",
    "        locations_map[loc] = next_location_id; next_location_id += 1\n",
    "    if ind and ind not in industries_map:\n",
    "        industries_map[ind] = next_industry_id; next_industry_id += 1\n",
    "\n",
    "    jid = next_job_id; next_job_id += 1\n",
    "    jobs_batch.append({\n",
    "        \"Job_ID\": jid, \"Job_Title\": jt, \"Job_Description\": jd,\n",
    "        \"Company_ID\": companies_map.get(cname),\n",
    "        \"Location_ID\": locations_map.get(loc),\n",
    "        \"Industry_ID\": industries_map.get(ind),\n",
    "        \"Salary_USD\": None, \"Employment_Type\": None,\n",
    "        \"Experience_Level\": None, \"Work_Setting\": None\n",
    "    })\n",
    "\n",
    "    if sks:\n",
    "        skills_found = re.split(r\"[;,|\\n]+\", str(sks))\n",
    "        for sk in [s.strip() for s in skills_found if s.strip()]:\n",
    "            if sk not in skills_map:\n",
    "                skills_map[sk] = next_skill_id; next_skill_id += 1\n",
    "            job_skills_batch.append({\"Job_ID\": jid, \"Skill_ID\": skills_map[sk]})\n",
    "\n",
    "    processed += 1\n",
    "    if len(jobs_batch) >= JOBS_BATCH:\n",
    "        flush_jobs(engine, jobs_batch, job_skills_batch)\n",
    "\n",
    "flush_jobs(engine, jobs_batch, job_skills_batch)\n",
    "print(f\"\\n✅ Processed {processed} rows in {(time.time()-start_time):.1f}s\")\n",
    "\n",
    "# Skip DB overwrites\n",
    "if DEMO_MODE:\n",
    "    print(\"\\n Skipping writing lookup tables (companies, locations, industries, skills).\")\n",
    "else:\n",
    "    with engine.begin() as conn:\n",
    "        pd.DataFrame([{\"Company_ID\": v, \"Company_Name\": k} for k, v in companies_map.items()]).to_sql('companies', con=conn, if_exists='replace', index=False)\n",
    "        pd.DataFrame([{\"Location_ID\": v, \"Location\": k} for k, v in locations_map.items()]).to_sql('locations', con=conn, if_exists='replace', index=False)\n",
    "        pd.DataFrame([{\"Industry_ID\": v, \"Industry\": k} for k, v in industries_map.items()]).to_sql('industries', con=conn, if_exists='replace', index=False)\n",
    "        pd.DataFrame([{\"Skill_ID\": v, \"Skill_Name\": k} for k, v in skills_map.items()]).to_sql('skills', con=conn, if_exists='replace', index=False)\n",
    "    print(\"Wrote lookup tables safely.\")\n",
    "\n",
    "print(\"\\n✅ Normalization demo complete.\")\n",
    "print(\"Companies:\", len(companies_map), \n",
    "      \"Locations:\", len(locations_map), \n",
    "      \"Industries:\", len(industries_map),\n",
    "      \"Skills:\", len(skills_map))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
